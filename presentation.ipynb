{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Model Quantization Principles\n",
    "\n",
    "This notebook covers the fundamentals of model quantization, including number formats, quantization strategies, and hands‑on examples for quantization and dequantization of float matrices.\n"
   ],
   "id": "ea6654b57ef6a35f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. Floating Point Numbers vs Fixed Point Numbers\n",
    "\n",
    "Floating point numbers represent real values with a sign bit, exponent field, and mantissa (fraction) field. Fixed point numbers use a fixed number of integer and fractional bits without an explicit exponent.\n",
    "\n",
    "**Float32 representation (32 bits total):**\n",
    "\n",
    "```\n",
    "| S (1 bit) | E (8 bits)        | M (23 bits)                         |\n",
    "|-----------|-------------------|-------------------------------------|\n",
    "```\n",
    "\n",
    "**Float16 representation (16 bits total):**\n",
    "\n",
    "```\n",
    "| S (1) | E (5)        | M (10)         |\n",
    "```\n",
    "\n",
    "**BFloat16 representation (16 bits total):**\n",
    "\n",
    "```\n",
    "| S (1) | E (8)        | M (7)          |\n",
    "```\n",
    "\n",
    "**int8 (8 bits signed):**\n",
    "\n",
    "```\n",
    "| S (1) | V (7 bits)      |\n",
    "```\n",
    "\n",
    "**uint8 (8 bits unsigned):**\n",
    "\n",
    "```\n",
    "| V (8 bits)              |\n",
    "```\n",
    "\n",
    "| Format   | Sign bits | Exponent bits | Mantissa bits | Range (approx.)             |\n",
    "| -------- | --------- | ------------- | ------------- | --------------------------- |\n",
    "| Float32  | 1         | 8             | 23            | \\~1.2×10^−38 to \\~3.4×10^38 |\n",
    "| Float16  | 1         | 5             | 10            | \\~6.1×10^−5 to \\~6.5×10^4   |\n",
    "| BFloat16 | 1         | 8             | 7             | \\~1.2×10^−38 to \\~3.4×10^38 |\n",
    "| int8     | 1         | –             | –             | −128 to 127                 |\n",
    "| uint8    | 0         | –             | –             | 0 to 255                    |\n"
   ],
   "id": "bc252da50c698882"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Quantization Approaches\n",
    "\n",
    "* **Uniform vs Non‑Uniform Quantization**: Uniform quantization divides the range into equal steps; non‑uniform uses variable spacing (e.g., logarithmic) to allocate more precision where data is dense.\n",
    "* **Symmetric vs Asymmetric Quantization**: Symmetric uses zero as the midpoint of the quant range; asymmetric allows a different offset (zero point) to handle non‑zero‑centered distributions.\n",
    "* **Layer‑wise vs Channel‑wise Quantization**: Layer‑wise uses a single scale/zero point per tensor; channel‑wise assigns separate parameters per output channel for finer granularity.\n",
    "* **Post‑Training Quantization vs Quantization‑Aware Training**: Post‑training quantization is applied after model training (fast but may lose accuracy); quantization‑aware training simulates quantization during training (more accurate, more compute).\n",
    "* **Clustering‑based Quantization**: Uses vector quantization (VQ) and product quantization (PQ) to cluster values or sub‑vectors into a small set of centroids (codebooks), encoding data by centroid indices.\n"
   ],
   "id": "78c69db576ddb133"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. Uniform, Symmetric Quantization\n",
    "\n",
    "This section demonstrates symmetric uniform quantization and its corresponding de‑quantization.\n",
    "\n",
    "### 3.1 Quantization Example (Uniform, Symmetric)\n",
    "\n",
    "We will quantize a small Float32 matrix to int8 using symmetric uniform quantization."
   ],
   "id": "b5010fd39176502e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T05:22:36.556562Z",
     "start_time": "2025-06-12T05:22:36.429162Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from typing import Tuple\n",
    "\n",
    "# Define a 3×4 float32 matrix\n",
    "def create_sample_matrix() -> np.ndarray:\n",
    "    return np.array([\n",
    "        [ 0.1, -0.5,  0.0,  1.0],\n",
    "        [ 2.5, -1.2,  0.7, -0.3],\n",
    "        [ 0.9,  1.5, -2.0,  0.2]\n",
    "    ], dtype=np.float32)\n",
    "\n",
    "# Quantization function for symmetric uniform quant\n",
    "def quantize_symmetric(\n",
    "    x: np.ndarray, num_bits: int\n",
    ") -> Tuple[np.ndarray, float]:\n",
    "    # Maximum absolute value\n",
    "    max_val = np.max(np.abs(x))\n",
    "    # Scale: map max_val -> max representable int\n",
    "    qmax = 2**(num_bits - 1) - 1\n",
    "    scale: float = max_val / qmax\n",
    "    # Quantize\n",
    "    q: np.ndarray = np.round(x / scale).astype(np.int8)\n",
    "    # Clip to range\n",
    "    q = np.clip(q, -qmax, qmax)\n",
    "    return q, scale\n",
    "\n",
    "# Apply quantization\n",
    "matrix = create_sample_matrix()\n",
    "quantized_matrix, scale = quantize_symmetric(matrix, num_bits=8)\n",
    "print('Original matrix:\\n', matrix)\n",
    "print('Quantized matrix (int8):\\n', quantized_matrix)\n",
    "print('Scale used:', scale)"
   ],
   "id": "591e45b36143be8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original matrix:\n",
      " [[ 0.1 -0.5  0.   1. ]\n",
      " [ 2.5 -1.2  0.7 -0.3]\n",
      " [ 0.9  1.5 -2.   0.2]]\n",
      "Quantized matrix (int8):\n",
      " [[   5  -25    0   51]\n",
      " [ 127  -61   36  -15]\n",
      " [  46   76 -102   10]]\n",
      "Scale used: 0.01968504\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "### 3.2 De‑quantization Example (Uniform, Symmetric)\n",
    "\n",
    "To restore the quantized values back to approximate float32 values:"
   ],
   "id": "ef724d89a41c9b74"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T05:22:36.611470Z",
     "start_time": "2025-06-12T05:22:36.608912Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def dequantize_symmetric(q: np.ndarray, scale: float) -> np.ndarray:\n",
    "    return q.astype(np.float32) * scale\n",
    "\n",
    "reconstructed_matrix = dequantize_symmetric(quantized_matrix, scale)\n",
    "print('Reconstructed matrix:\\n', reconstructed_matrix)"
   ],
   "id": "f13da7ae7b2c5c91",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstructed matrix:\n",
      " [[ 0.09842519 -0.492126    0.          1.003937  ]\n",
      " [ 2.5        -1.2007874   0.70866144 -0.2952756 ]\n",
      " [ 0.9055118   1.496063   -2.007874    0.19685039]]\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This completes a basic demonstration of quantization and de‑quantization using symmetric uniform quantization on a small float32 matrix. Adjustments (e.g., zero‑point for asymmetric) can be added further.",
   "id": "8b098949f1e74bf1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4. Clustering-based Quantization\n",
    "\n",
    "Clustering-based quantization uses vector quantization (VQ) or product quantization (PQ) to map high-dimensional float values to discrete indices referencing a small set of centroids (the codebook).\n",
    "\n",
    "### 4.1 Vector Quantization (VQ)\n",
    "\n",
    "In VQ, each scalar (or vector) is treated as a sample and clustered into $K$ centroids:\n",
    "\n",
    "1. **Form samples**: Flatten the matrix into a 1D list of values (or treat each row as a vector).\n",
    "2. **K-Means clustering**: Compute $K$ centroids.\n",
    "3. **Quantize**: Replace each sample by the index of its nearest centroid, producing an index matrix of the same shape.\n",
    "4. **Store**: Save the centroid array (codebook) and the index matrix.\n"
   ],
   "id": "26ca157b791b71de"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T05:22:39.801641Z",
     "start_time": "2025-06-12T05:22:36.618533Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "# Using the same sample matrix\n",
    "data = create_sample_matrix()                # shape (3, 4)\n",
    "flat_data = data.reshape(-1, 1)              # treat each value as a 1D sample\n",
    "\n",
    "# Train k-means\n",
    "K = 4                                       # number of centroids\n",
    "kmeans = KMeans(n_clusters=K, random_state=0).fit(flat_data)\n",
    "codebook = kmeans.cluster_centers_.flatten()  # shape (K,)\n",
    "\n",
    "# Quantize: assign each value to nearest centroid\n",
    "indices = kmeans.predict(flat_data)         # shape (12,)\n",
    "index_matrix = indices.reshape(data.shape)  # shape (3, 4)\n",
    "\n",
    "print('Codebook (centroids):', codebook)\n",
    "print('Index matrix:\\n', index_matrix)"
   ],
   "id": "bd8912810668b136",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Codebook (centroids): [ 1.025      -1.6         2.5        -0.10000001]\n",
      "Index matrix:\n",
      " [[3 3 3 0]\n",
      " [2 1 0 3]\n",
      " [0 0 1 3]]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T05:22:39.868788Z",
     "start_time": "2025-06-12T05:22:39.842223Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 3) Dequantize: reconstruct approximate floats\n",
    "reconstructed_flat = codebook[indices]\n",
    "reconstructed = reconstructed_flat.reshape(data.shape)\n",
    "print('Reconstructed matrix:\\n', reconstructed)"
   ],
   "id": "325238f6b72f4a56",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstructed matrix:\n",
      " [[-0.10000001 -0.10000001 -0.10000001  1.025     ]\n",
      " [ 2.5        -1.6         1.025      -0.10000001]\n",
      " [ 1.025       1.025      -1.6        -0.10000001]]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "### 4.2 Product Quantization (PQ)\n",
    "\n",
    "PQ splits each row vector into $M$ sub-vectors and applies VQ within each subspace:\n",
    "\n",
    "1. **Split** each row into $M$ equal-length sub-vectors.\n",
    "2. **Train** K-Means separately on each subspace to obtain $M$ codebooks.\n",
    "3. **Encode**: For each sub-vector, store the centroid index, resulting in an index matrix of shape $(num\\_rows, M)$.\n",
    "4. **Store**: Save all $M$ codebooks and the index matrix.\n",
    "\n",
    "**Benefits of PQ in Computation**\n",
    "\n",
    "* **Memory-bandwidth and cache efficiency:** By compressing weights to small integer indices (e.g., a few bits per sub-vector), the number of bytes fetched from memory during matrix operations is reduced, alleviating memory-bound bottlenecks on modern hardware.\n",
    "* **Lookup-based dot-products:** Instead of reconstructing every float weight, small lookup tables of dot-products between input sub-vectors and each centroid are precomputed. At inference, each sub-vector multiply becomes a single table lookup plus an addition, reducing the number of floating-point multiplies."
   ],
   "id": "2f3432cf74d050ed"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "#### 4.2.1 PQ Quantization & Dequantization\n"
   ],
   "id": "347fffee1f4e2d71"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T05:22:40.013497Z",
     "start_time": "2025-06-12T05:22:39.926067Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "from typing import List\n",
    "\n",
    "# Prepare data\n",
    "matrix = create_sample_matrix()             # shape (3, 4)\n",
    "n, d = matrix.shape\n",
    "M = 2                                      # number of subspaces\n",
    "pc = 3                                     # clusters per subspace\n",
    "sub_dim = d // M                           # sub-vector dimension\n",
    "\n",
    "# Split into subspaces\n",
    "subspaces = [matrix[:, i*sub_dim:(i+1)*sub_dim] for i in range(M)]\n",
    "codebooks: List[np.ndarray] = []\n",
    "codes: List[np.ndarray] = []\n",
    "for sub in subspaces:\n",
    "    kmeans = KMeans(n_clusters=pc, random_state=0).fit(sub)\n",
    "    codebooks.append(kmeans.cluster_centers_)  # shape (pc, sub_dim)\n",
    "    codes.append(kmeans.predict(sub))          # shape (n,)\n",
    "\n",
    "print('Codebooks:\\n', codebooks)\n",
    "\n",
    "# Combined codes (n x M)\n",
    "pq_codes = np.stack(codes, axis=1)\n",
    "print('PQ Codes:\\n', pq_codes)\n",
    "\n",
    "# Dequantize: reconstruct and concatenate\n",
    "reconstructed_pq = np.hstack([codebooks[i][pq_codes[:, i]] for i in range(M)])\n",
    "print('PQ reconstructed matrix:\\n', reconstructed_pq)"
   ],
   "id": "6f4f7dec6129e49b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Codebooks:\n",
      " [array([[ 2.5       , -1.2       ],\n",
      "       [ 0.9       ,  1.5       ],\n",
      "       [ 0.10000002, -0.5       ]], dtype=float32), array([[ 0.70000005, -0.30000004],\n",
      "       [-2.        ,  0.2       ],\n",
      "       [ 0.        ,  1.        ]], dtype=float32)]\n",
      "PQ Codes:\n",
      " [[2 2]\n",
      " [0 0]\n",
      " [1 1]]\n",
      "PQ reconstructed matrix:\n",
      " [[ 0.10000002 -0.5         0.          1.        ]\n",
      " [ 2.5        -1.2         0.70000005 -0.30000004]\n",
      " [ 0.9         1.5        -2.          0.2       ]]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "#### 4.2.2 Lookup-based Dot-Product Inference"
   ],
   "id": "8f1719fa210c2aeb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "At inference time, given an input activation (e.g., a query or key) vector in float32:\n",
    "\n",
    "1. Split it into the same $M$ sub-vectors as used for weight PQ.\n",
    "\n",
    "2. Compute lookup tables: for each subspace $i$, build a table of size $K$ (number of centroids) where\n",
    "\n",
    "    ```python\n",
    "    L_i[j] = np.dot(query_subs[i], codebooks[i][j])  # j=0..K-1\n",
    "    ```\n",
    "    This pre‑computes the dot-product (or distance) between the `query sub-vector` and `each centroid` in subspace $i$.\n",
    "\n",
    "3. Dot-product via lookup: to compute the dot-product between this activation and any weight row $r$ (represented by indices in pq_codes), simply sum the corresponding lookups:\n",
    "\n",
    "```python\n",
    "dot(query, weight_row_r) = sum(\n",
    "    L_i[ pq_codes[r, i] ]\n",
    "    for i in range(M)\n",
    ")\n",
    "```\n",
    "\n",
    "By doing this, each dot-product uses only $M$ lookups and $M-1$ additions, instead of $d$ multiplies and full weight reconstruction, leading to significant computational and memory-bandwidth savings."
   ],
   "id": "6c80a3f01de7f73b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T05:22:40.043896Z",
     "start_time": "2025-06-12T05:22:40.040005Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Given a query activation vector\n",
    "query = np.array([0.2, -0.1, 0.5, 1.0], dtype=np.float32)  # shape (4,)\n",
    "print('Query:\\n', query)\n",
    "\n",
    "# Split query into same subspaces\n",
    "query_subs = [query[i*sub_dim : (i+1)*sub_dim] for i in range(M)]\n",
    "print('Query subspaced:\\n', query_subs)\n",
    "\n",
    "# Build lookup tables: dot(query_sub, centroid) for each centroid\n",
    "lookup_tables = [\n",
    "    np.dot(query_subs[i], codebooks[i].T)  # shape (pc,)\n",
    "    for i in range(M)\n",
    "]\n",
    "print('Lookup tables:\\n', lookup_tables)\n",
    "\n",
    "# Compute dot-product for each row of reconstructed weights via lookup\n",
    "#    dot = sum over subspaces of lookup_tables[i][pq_codes[row, i]]\n",
    "\n",
    "dot_products: list[np.float32] = []\n",
    "for row_idx in range(n):\n",
    "    dp = sum(\n",
    "        lookup_tables[i][pq_codes[row_idx, i]]\n",
    "        for i in range(M)\n",
    "    )\n",
    "    dot_products.append(dp)\n",
    "\n",
    "print('Dot-products via PQ lookup:\\n', dot_products)"
   ],
   "id": "deb4be23699644ae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:\n",
      " [ 0.2 -0.1  0.5  1. ]\n",
      "Query subspaced:\n",
      " [array([ 0.2, -0.1], dtype=float32), array([0.5, 1. ], dtype=float32)]\n",
      "Lookup tables:\n",
      " [array([0.62      , 0.02999999, 0.07000001], dtype=float32), array([ 0.04999998, -0.8       ,  1.        ], dtype=float32)]\n",
      "Dot-products via PQ lookup:\n",
      " [np.float32(1.07), np.float32(0.66999996), np.float32(-0.77000004)]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "Here, each dot-product uses only $M$ lookups and $M-1$ additions instead of $d$ multiplies, yielding faster inference when $d \\gg M$.\n",
    "\n",
    "This section shows both simple VQ and PQ quantization and dequantization, as well as an optimized inference strategy using lookup-based dot-products. You can adjust **K** (number of centroids) or **M** (number of subspaces) to trade off compression, accuracy, and computational cost.\n"
   ],
   "id": "b97fe4601abb0f75"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "599d14b9cdaee521"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
